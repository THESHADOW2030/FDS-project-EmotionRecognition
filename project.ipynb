{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Convolutional Neural Network\n",
    "\n",
    "We will use a convolutional neural network to detect the emotions. \n",
    "We will train our model using the FER2013 dataset. Then, using the trained model, we will detect the emotions in the faces detected in the video stream captured by the camera or the video file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 17:02:29.036272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 17:02:29.036474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 17:02:29.036569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 17:02:29.036693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 17:02:29.036920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 17:02:29.037007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/theshadow/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py:1769: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow  as  tf\n",
    "from  tensorflow  import  keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "import numpy as  np\n",
    "import matplotlib.pyplot  as  plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import cv2 as cv\n",
    "import pandas  as  pd\n",
    "import tqdm as tqdm\n",
    "\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "#print the number of GPU\n",
    "\n",
    "print ( \"Num GPUs Available: \" ,  len ( tf.config.experimental.list_physical_devices ( 'GPU' )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and differentiate between training and testing data (they are spit in two folders, one for training and one for testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetToUse = \"GoogleFer\" # \"CK+48\" or \"FER2013\" or \"GoogleFer\" or \"datasetGigante\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FER2013 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "if datasetToUse == \"FER2013\":\n",
    "        \n",
    "        path = \"./dataset/FER2013/\"\n",
    "        test_path = path + \"test/\"\n",
    "        train_path = path + \"train/\"\n",
    "\n",
    "\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        val_x = []\n",
    "        val_y = []\n",
    "\n",
    "        #load the train data\n",
    "\n",
    "        classes = { \"angry\" : 0,  \"disgust\" : 1,  \"fear\" : 2,  \"happy\" : 3,  \"sad\" : 4,  \"surprise\" : 5,  \"neutral\" : 6}\n",
    "        classesDiz2 = { 0 : \"angry\" ,  1 : \"disgust\" ,  2 : \"fear\" ,  3 : \"happy\" ,  4 : \"sad\" ,  5 : \"surprise\" ,  6 : \"neutral\" }\n",
    "\n",
    "        data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        batch_size = 32\n",
    "        # Preprocess all test images\n",
    "        train_generator = data_generator.flow_from_directory(\n",
    "                train_path,\n",
    "                target_size=(48, 48),\n",
    "                batch_size=64,\n",
    "                color_mode=\"grayscale\",\n",
    "                class_mode='categorical')\n",
    "\n",
    "        # Preprocess all train images\n",
    "        validation_generator = data_generator.flow_from_directory(\n",
    "                test_path,\n",
    "                target_size=(48, 48),\n",
    "                batch_size=64,\n",
    "                color_mode=\"grayscale\",\n",
    "                class_mode='categorical')\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape:  (32645, 48, 48)\n",
      "train_y shape:  (32645, 8)\n",
      "val_x shape:  (8166, 48, 48)\n",
      "val_y shape:  (8166, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if datasetToUse == \"GoogleFer\":\n",
    "\n",
    "\n",
    "        path = \"./dataset/GoogleFer/\"\n",
    "        test_path = path + \"val/\"\n",
    "        train_path = path + \"train/\"\n",
    "\n",
    "        classes = { \"anger\" : 0,  \"contempt\" : 1,  \"disgust\" : 2,  \"fear\" : 3,  \"happiness\" : 4,  \"sadness\" : 5,  \"surprise\" : 6,  \"neutral\" : 7}\n",
    "\n",
    "        classesReversed = { 0 : \"anger\" ,  1 : \"contempt\" ,  2 : \"disgust\" ,  3 : \"fear\" ,  4 : \"happiness\" ,  5 : \"sadness\" ,  6 : \"surprise\" ,  7 : \"neutral\" }\n",
    "        num_classes = 8\n",
    "\n",
    "        batch_size = 32\n",
    "        \n",
    "\n",
    "\n",
    "        train_x = []\n",
    "        train_y = []\n",
    "        val_x = []\n",
    "        val_y = []\n",
    "\n",
    "        #load the train data\n",
    "\n",
    "        \n",
    "\n",
    "        contClassesTrain = { \"anger\" : 0,  \"contempt\" : 0,  \"disgust\" : 0,  \"fear\" : 0,  \"happiness\" : 0,  \"sadness\" : 0,  \"surprise\" : 0,  \"neutral\" : 0}\n",
    "        contClassesTest = { \"anger\" : 0,  \"contempt\" : 0,  \"disgust\" : 0,  \"fear\" : 0,  \"happiness\" : 0,  \"sadness\" : 0,  \"surprise\" : 0,  \"neutral\" : 0}\n",
    "\n",
    "\n",
    "\n",
    "        for i in classes:\n",
    "                #convert i to upper case\n",
    "                #i = i.upper()    \n",
    "                path = os.path.join(train_path, i.upper())\n",
    "                 \n",
    "                for img in os.listdir(path):\n",
    "                        img_array = cv2.imread (os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                        #new_array = cv2.resize(img_array, (48, 48))\n",
    "                        train_x.append(img_array)\n",
    "                        train_y.append(classes[i])\n",
    "                        contClassesTrain[i] = contClassesTrain[i] + 1\n",
    "\n",
    "        #load the test data\n",
    "        for i in classes:\n",
    "                #i = i.upper()  \n",
    "                path = os.path.join(test_path, i.upper())\n",
    "               \n",
    "                 \n",
    "                for img in os.listdir(path):\n",
    "                        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                        #new_array = cv2.resize(img_array, (48, 48))\n",
    "                        val_x.append(img_array)\n",
    "                        val_y.append(classes[i])\n",
    "                        contClassesTest[i] = contClassesTest[i] + 1\n",
    "\n",
    "        #convert the val_x and train_x to numpy array\n",
    "        train_x = np.array(train_x)\n",
    "        train_y = keras.utils.to_categorical(train_y, 8)\n",
    "        val_x = np.array(val_x)\n",
    "        val_y = keras.utils.to_categorical(val_y, 8)\n",
    "\n",
    "        print ( \"train_x shape: \" , train_x.shape)\n",
    "        print ( \"train_y shape: \" , train_y.shape)\n",
    "        print ( \"val_x shape: \" , val_x.shape)\n",
    "        print ( \"val_y shape: \" , val_y.shape)\n",
    "\n",
    "\n",
    "        data_generator = ImageDataGenerator(\n",
    "                                        rescale=1./255,\n",
    "                                        rotation_range=30,\n",
    "                                        width_shift_range=0.3,\n",
    "                                        height_shift_range=0.3,        \n",
    "                                        zoom_range=0.3\n",
    "                                        )\n",
    "        \n",
    "\n",
    "        #reshape the data\n",
    "        train_x = train_x.reshape(train_x.shape[0], 48, 48, 1)\n",
    "        val_x = val_x.reshape(val_x.shape[0], 48, 48, 1)\n",
    "\n",
    "        train_generator = data_generator.flow(train_x, train_y, batch_size=batch_size)\n",
    "        validation_generator = data_generator.flow(val_x, val_y, batch_size=batch_size)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        randomIndex = random.randint(0, len(train_x))\n",
    "        #plot the first image\n",
    "        plt.imshow(train_x[randomIndex].reshape(48, 48), cmap='gray')\n",
    "        #label it\n",
    "        plt.title(classesReversed[np.argmax(train_y[randomIndex])])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        #plot the contClassesTrain\n",
    "        plt.bar(range(len(contClassesTrain)), list(contClassesTrain.values()), align='center')\n",
    "        plt.xticks(range(len(contClassesTrain)), list(contClassesTrain.keys()))\n",
    "        plt.show()\n",
    "\n",
    "        #plot the contClassesTest\n",
    "        plt.bar(range(len(contClassesTest)), list(contClassesTest.values()), align='center')\n",
    "        plt.xticks(range(len(contClassesTest)), list(contClassesTest.keys()))\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CK+ dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CK+ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load the data\n",
    "if datasetToUse == \"CK+48\":\n",
    "    dataset_path = \"./dataset/CK+48/\"\n",
    "\n",
    "    label_images = {\n",
    "        \"anger\" : [],\n",
    "        \"contempt\" : [],\n",
    "        \"disgust\" : [],\n",
    "        \"fear\" : [],\n",
    "        \"happy\" : [],\n",
    "        \"sadness\" : [],\n",
    "        \"surprise\" : []\n",
    "    }\n",
    "\n",
    "    for folder in os.listdir(dataset_path):\n",
    "        for file in os.listdir(dataset_path + folder):\n",
    "            image = cv.imread(dataset_path + folder + \"/\" + file, 0)\n",
    "\n",
    "            label_images[folder].append(np.array(image))\n",
    "\n",
    "    #for each label, take 80% of the images for training and 20% for testing\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    val_x = []\n",
    "    val_y = []\n",
    "\n",
    "    classes = { \"anger\" : 0,  \"contempt\" : 1,  \"disgust\" : 2,  \"fear\" : 3,  \"happy\" : 4,  \"sadness\" : 5,  \"surprise\" : 6}\n",
    "    classesDiz2 = { 0 : \"anger\" ,  1 : \"contempt\" ,  2 : \"disgust\" ,  3 : \"fear\" ,  4 : \"happy\" ,  5 : \"sadness\" ,  6 : \"surprise\" }\n",
    "\n",
    "    for label in label_images:\n",
    "        cont = 0\n",
    "        for image in label_images[label]:\n",
    "            if cont < len(label_images[label]) * 0.8:\n",
    "                train_x.append(image)\n",
    "                train_y.append(classes[label])\n",
    "            else:\n",
    "                val_x.append(image)\n",
    "                val_y.append(classes[label])\n",
    "            cont += 1\n",
    "            \n",
    "\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "\n",
    "    val_x = np.array(val_x)\n",
    "    val_y = np.array(val_y)\n",
    "\n",
    "    #print the shape of the data\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    #reshape the data\n",
    "    train_x = train_x.reshape(train_x.shape[0], 48, 48, 1)\n",
    "    val_x = val_x.reshape(val_x.shape[0], 48, 48, 1)\n",
    "\n",
    "\n",
    "    print ( \"Train data shape: \" , train_x.shape)\n",
    "    print ( \"Train labels shape: \" , train_y.shape)\n",
    "    print ( \"Test data shape: \" , val_x.shape)\n",
    "    print ( \"Test labels shape: \" , val_y.shape)\n",
    "\n",
    "\n",
    "    #convert the labels to categorical\n",
    "    train_y = keras.utils.to_categorical(train_y, 7)\n",
    "    val_y = keras.utils.to_categorical(val_y, 7)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    # Preprocess all test images\n",
    "    train_generator = data_generator.flow(\n",
    "            train_x,\n",
    "            train_y,    #as the batch size, select the entire dataset\n",
    "            \n",
    "    )\n",
    "    \n",
    "\n",
    "    # Preprocess all train images\n",
    "    validation_generator = data_generator.flow(\n",
    "            val_x,\n",
    "            val_y,\n",
    "            \n",
    "    )\n",
    "\n",
    "\n",
    "    num_classes = 7\n",
    "    classes = { \"anger\" : 0,  \"contempt\" : 1,  \"disgust\" : 2,  \"fear\" : 3,  \"happy\" : 4,  \"sadness\" : 5,  \"surprise\" : 6}\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Gigante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if datasetToUse == \"datasetGigante\":\n",
    "\n",
    "    path = \"./dataset/datasetGigante/\"\n",
    "\n",
    "    #load the CVS that contains the labels\n",
    "    labels = pd.read_csv(path + \"labels.csv\")\n",
    "\n",
    "   #plot the first rows of the labels\n",
    "    print (labels.head())\n",
    "\n",
    "    \n",
    "    #get the number of unique labels\n",
    "    print ( \"Number of unique labels: \" , len(labels.label.unique()))\n",
    "\n",
    "    classes = { \"anger\" : 0,  \"contempt\" : 1,  \"disgust\" : 2,  \"fear\" : 3,  \"happy\" : 4,  \"sad\" : 5,  \"surprise\" : 6,  \"neutral\" : 7}\n",
    "\n",
    "    classesReversed = { 0 : \"anger\" ,  1 : \"contempt\" ,  2 : \"disgust\" ,  3 : \"fear\" ,  4 : \"happy\" ,  5 : \"sad\" ,  6 : \"surprise\" ,  7 : \"neutral\" }\n",
    "\n",
    "    #create a dictionary that contains as key the label and as value an empty list\n",
    "    label_images = {\n",
    "        \"anger\" : [],\n",
    "        \"contempt\" : [],\n",
    "        \"disgust\" : [],\n",
    "        \"fear\" : [],\n",
    "        \"happy\" : [],\n",
    "        \"sad\" : [],\n",
    "        \"surprise\" : [],\n",
    "        \"neutral\" : []\n",
    "    }\n",
    "\n",
    "    for folder in os.listdir(path):\n",
    "\n",
    "        #check whether the folder is actually a folder\n",
    "        if not os.path.isdir(path + folder):\n",
    "            continue\n",
    "        #use tqdm to show the progress\n",
    "        print ( \"Loading images from \" , folder)\n",
    "        for file in tqdm.tqdm(os.listdir(path + folder)):\n",
    "            #the image is in color\n",
    "            imagePath = path + folder + \"/\" + file\n",
    "            imageName = folder + \"/\" + file\n",
    "            \n",
    "            #in the csv, there are two columns: the image name called pth and the label\n",
    "            #get the label of the image\n",
    "            label = labels.loc[labels['pth'] == imageName, 'label'].iloc[0]\n",
    "            \n",
    "            #load the image is in color\n",
    "            image = cv.imread(imagePath, cv.IMREAD_GRAYSCALE)\n",
    "            #resize the image\n",
    "            image = cv.resize(image, (48, 48))\n",
    "            \n",
    "            #add the image to the dictionary\n",
    "            label_images[label].append(np.array(image))\n",
    "\n",
    "    #plot 5 images per label\n",
    "    for label in label_images:\n",
    "        for i in range(5):\n",
    "            plt.imshow(label_images[label][i], cmap = \"gray\")\n",
    "            plt.title(label)\n",
    "            plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    #for each label, take 80% of the images for training and 20% for testing\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    val_x = []\n",
    "    val_y = []\n",
    "    for label in label_images:\n",
    "        cont = 0\n",
    "        for image in label_images[label]:\n",
    "            if cont < len(label_images[label]) * 0.8:\n",
    "                train_x.append(image)\n",
    "                train_y.append(classes[label])\n",
    "            else:\n",
    "                val_x.append(image)\n",
    "                val_y.append(classes[label])\n",
    "            cont += 1\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    val_x = np.array(val_x)\n",
    "    val_y = np.array(val_y)\n",
    "    #reshape the data\n",
    "    train_x = train_x.reshape(train_x.shape[0], 48, 48, 1)\n",
    "    val_x = val_x.reshape(val_x.shape[0], 48, 48, 1)\n",
    "    #print the shape of the data\n",
    "    print ( \"Train data shape: \" , train_x.shape)\n",
    "    print ( \"Train labels shape: \" , train_y.shape)\n",
    "    print ( \"Test data shape: \" , val_x.shape)\n",
    "    print ( \"Test labels shape: \" , val_y.shape)\n",
    "    #convert the labels to categorical\n",
    "    train_y = keras.utils.to_categorical(train_y, 8)\n",
    "    val_y = keras.utils.to_categorical(val_y, 8)\n",
    "\n",
    "    data_generator = ImageDataGenerator(rescale=1./255)\n",
    "    # Preprocess all test images\n",
    "    train_generator = data_generator.flow(\n",
    "            train_x,\n",
    "            train_y,    #as the batch size, select the entire dataset\n",
    "    )\n",
    "    # Preprocess all train images\n",
    "    validation_generator = data_generator.flow(\n",
    "            val_x,\n",
    "            val_y,\n",
    "    )\n",
    "    num_classes = 8\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AffectNet dataset\n",
    "https://www.kaggle.com/datasets/tom99763/affectnethq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Convolution2D, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D, MaxPool2D\n",
    "from keras.models import Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(48, 48, 1)\n",
    "weight_decay = 1e-4\n",
    "\n",
    "modelType = \"EmotionNet\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def EmotionNet():\n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, kernel_regularizer=keras.regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return model\n",
    "    \n",
    "\n",
    "\n",
    "def modelFromYoutube():\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def ResNet():\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    pass\n",
    "                \n",
    "# create the model\n",
    "\n",
    "if modelType == \"EmotionNet\":\n",
    "    model = EmotionNet()\n",
    "elif modelType == \"modelFromYoutube\":\n",
    "    model = modelFromYoutube()\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=6,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    lr_scheduler,\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "train_x = train_x / 255.\n",
    "val_x = val_x / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, validation_data=validation_generator, epochs=50, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(val_x, val_y))\n",
    "\n",
    "print(model.evaluate(validation_generator))\n",
    "\n",
    "#plot the accuracy and loss\n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model as model name\n",
    "model.save(\"modelEmotionNet+GoogleFer66.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the module to read from webcam \n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "#import accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below captures a video stream of the camera and displays it in the notebook. The video stream is captured using the OpenCV library. \n",
    "If we want to capture from a video file, we can use the following code:\n",
    "\n",
    "cv.VideoCapture('project_video.mp4')\n",
    "\n",
    "On the other hand, if we want to use the camera, we can use the following code:\n",
    "\n",
    "cv.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoPath = \"METTERE QUI IL PATH DEL VIDEO\"\n",
    "\n",
    "if videoPath == \"METTERE QUI IL PATH DEL VIDEO\" or videoPath == \"\":\n",
    "    cap = cv.VideoCapture(0)\n",
    "else:\n",
    "    cap = cv.VideoCapture(videoPath)\n",
    "\n",
    "#there are 8 emotions\n",
    "num_classes = 8\n",
    "\n",
    "classes = classesReversed\n",
    "print(classes)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will choose if we want to dected the frontal faces, the profile or both. We will use the frontal face cascade classifier by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haarDetectionMode = \"profile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haarDetectionMode = \"profileAndFrontal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haarDetectionMode = \"frontal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveCroppedFaces = False\n",
    "predictEmotions = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function detect faces uses haar cascade to detect faces in the frame. \n",
    "There are two versions of haar cascades, one for profile faces and one for frontal faces.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFaces(frame):\n",
    "\n",
    "    detectedFaces = []\n",
    "\n",
    "\n",
    "    #use haar cascade to detect faces\n",
    "    if haarDetectionMode == \"frontal\" or haarDetectionMode == \"profileAndFrontal\":\n",
    "        faceCascadeFrontal = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        facesFrontal = faceCascadeFrontal.detectMultiScale(frame, 1.1, 4)\n",
    "\n",
    "        detectedFaces.extend(facesFrontal)\n",
    "\n",
    "    elif haarDetectionMode == \"profile\" or haarDetectionMode == \"profileAndFrontal\":\n",
    "        faceCascadeProfile = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_profileface.xml')\n",
    "        facesProfile = faceCascadeProfile.detectMultiScale(frame, 1.1, 4)\n",
    "\n",
    "        detectedFaces.extend(facesProfile)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return detectedFaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawRectangleFace(frame, facesCoordinates):\n",
    "    #draw the rectangle around the face\n",
    "    frameWithRectangle = frame.copy()\n",
    "    for (x, y, w, h) in facesCoordinates:\n",
    "        cv.rectangle(frameWithRectangle, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "    return frameWithRectangle\n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImage(image):\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictEmotion(face):\n",
    "    #resize the image\n",
    "    face = cv.resize(face, (48, 48))\n",
    "\n",
    "    #convert the image to float\n",
    "    face = face.astype('float32')\n",
    "    #normalize the image\n",
    "    face /= 255\n",
    "    #reshape the image\n",
    "    face = face.reshape(1, 48, 48, 1)\n",
    "    #predict the emotion\n",
    "    emotion = model.predict(face)\n",
    "    return emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictEmotions:\n",
    "    #load the model\n",
    "    model = keras.models.load_model('modelEmotionNet+GoogleFer66.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeEmotionOnImage(frame, facesCoordinates, emotions):\n",
    "    frameWithEmotion = frame.copy()\n",
    "    for (x, y, w, h), emotion in zip(facesCoordinates, emotions):\n",
    "        #get the emotion with the highest probability and write the confidence\n",
    "        emotion1 = classes[np.argmax(emotion)]\n",
    "        confidence = np.max(emotion)\n",
    "        cv.putText(frameWithEmotion, emotion1 + \" \" + str(confidence), (x, y), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    return frameWithEmotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def showVideo():\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Unable to capture video\")\n",
    "        exit()\n",
    "        \n",
    "    \n",
    "    #flip the image\n",
    "    frame = cv.flip(frame,1)\n",
    "    grayFrame = frame\n",
    "    #convert the image to grayscale\n",
    "    if frame is not None:\n",
    "        grayFrame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    #detect the face\n",
    "    facesCoordinates = detectFaces(grayFrame)\n",
    "\n",
    "    #draw the rectangle around the face\n",
    "    frameToShow = drawRectangleFace(frame, facesCoordinates)\n",
    "\n",
    "    if predictEmotions:\n",
    "\n",
    "        emotions = []\n",
    "        for (x, y, w, h) in facesCoordinates:\n",
    "            #crop the face\n",
    "            face = grayFrame[y:y+h, x:x+w]\n",
    "            face = cv.resize(face, (48, 48))\n",
    "            #convert to numpy array\n",
    "            face = np.array(face)\n",
    "            face.reshape(48, 48, 1)\n",
    "\n",
    "            #save the face\n",
    "            if saveCroppedFaces:\n",
    "                cv.imwrite(\"./savedFaces/face.jpg\", face)\n",
    "            \n",
    "\n",
    "\n",
    "            #predict the emotion\n",
    "            emotion = predictEmotion(face)\n",
    "            emotions.append(emotion)\n",
    "            \n",
    "\n",
    "        frameToShow = writeEmotionOnImage(frameToShow, facesCoordinates, emotions)\n",
    "\n",
    "\n",
    "    #display the image\n",
    "    cv.imshow('frame',frameToShow)\n",
    "    ret = True\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        ret = False\n",
    "        \n",
    "    return ret, frame, facesCoordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = True\n",
    "while ret:\n",
    "    \n",
    "    \n",
    "\n",
    "    #show the video with the face detected\n",
    "    ret, frame, facesCoordinates = showVideo()\n",
    "\n",
    "\n",
    "                \n",
    "            \n",
    "    \n",
    "#release the camera\n",
    "cap.release()\n",
    "#close all windows\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the vgg16 model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#extract the features from the images\n",
    "def extractFeatures(images):\n",
    "    features = featuatureExtractionModel.predict(images)\n",
    "    #reshape the features\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "featuatureExtractionModel = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "#freeze the layers\n",
    "for layer in featuatureExtractionModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "val_x = []\n",
    "val_y = []\n",
    "\n",
    "\n",
    "for folder in os.listdir(\"./dataset/GoogleFer/train/\"):\n",
    "    for file in os.listdir(\"./dataset/GoogleFer/train/\" + folder):\n",
    "        image = cv.imread(\"./dataset/GoogleFer/train/\" + folder + \"/\" + file)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        train_x.append(image)\n",
    "        train_y.append(folder)\n",
    "\n",
    "for folder in os.listdir(\"./dataset/GoogleFer/val/\"):\n",
    "    for file in os.listdir(\"./dataset/GoogleFer/val/\" + folder):\n",
    "        image = cv.imread(\"./dataset/GoogleFer/val/\" + folder + \"/\" + file)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        val_x.append(image)\n",
    "        val_y.append(folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "val_x = np.array(val_x)\n",
    "val_y = np.array(val_y)\n",
    "\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "train_x = extractFeatures(train_x)\n",
    "val_x = extractFeatures(val_x)\n",
    "print(\"Finished extracting features\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a softmax classifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(train_x, train_y)\n",
    "\n",
    "#evaluate the model\n",
    "print(classifier.score(val_x, val_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction using my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 21:09:03.198594: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-14 21:09:03.470875: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-14 21:09:03.610788: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-14 21:09:04.422926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/theshadow/Documents/MLexercises/TES/lib/\n",
      "2022-12-14 21:09:04.422997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/theshadow/Documents/MLexercises/TES/lib/\n",
      "2022-12-14 21:09:04.423001: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-14 21:09:05.772429: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-14 21:09:05.803043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 21:09:05.834505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 21:09:05.834630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 21:09:06.551511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 21:09:06.552263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 21:09:06.552454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 21:09:06.552612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3614 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-12-14 21:09:06.555626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 21:09:06.555788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 21:09:06.555893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Convolution2D, BatchNormalization, Activation, AveragePooling2D, GlobalAveragePooling2D, MaxPool2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow  as  tf\n",
    "from  tensorflow  import  keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "import numpy as  np\n",
    "import matplotlib.pyplot  as  plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import cv2 as cv\n",
    "import pandas  as  pd\n",
    "import tqdm as tqdm\n",
    "\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "#print the number of GPU\n",
    "\n",
    "print ( \"Num GPUs Available: \" ,  len ( tf.config.experimental.list_physical_devices ( 'GPU' )))\n",
    "\n",
    "#import the module to read from webcam \n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "#import accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 17:44:01.350225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 17:44:01.350402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 17:44:01.350479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 17:44:01.350597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 17:44:01.350677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-14 17:44:01.350745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3678 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#load my model \n",
    "model = keras.models.load_model('modelEmotionNet+GoogleFer66.h5')\n",
    "\n",
    "flag = True\n",
    "\n",
    "\n",
    "#create a new model starting from model until flatten\n",
    "newModel = keras.models.Model(inputs=model.input, outputs=model.get_layer('dropout_3').output)\n",
    "# print(\"New model:\")\n",
    "# newModel.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32645, 48, 48)\n",
      "(32645,)\n",
      "(8166, 48, 48)\n",
      "(8166,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "val_x = []\n",
    "val_y = []\n",
    "\n",
    "\n",
    "for folder in os.listdir(\"./dataset/GoogleFer/train/\"):\n",
    "    for file in os.listdir(\"./dataset/GoogleFer/train/\" + folder):\n",
    "        image = cv.imread(\"./dataset/GoogleFer/train/\" + folder + \"/\" + file)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        #convert to grayscale\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        train_x.append(image)\n",
    "        train_y.append(folder)\n",
    "\n",
    "for folder in os.listdir(\"./dataset/GoogleFer/val/\"):\n",
    "    for file in os.listdir(\"./dataset/GoogleFer/val/\" + folder):\n",
    "        image = cv.imread(\"./dataset/GoogleFer/val/\" + folder + \"/\" + file)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        #convert to grayscale\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        val_x.append(image)\n",
    "        val_y.append(folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "val_x = np.array(val_x)\n",
    "val_y = np.array(val_y)\n",
    "\n",
    "train_x = train_x / 255.0\n",
    "val_x = val_x / 255.0\n",
    "\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(model, images):\n",
    "    features = model.predict(images)\n",
    "    #reshape the features\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021/1021 [==============================] - 6s 5ms/step\n",
      "256/256 [==============================] - 1s 5ms/step\n",
      "Finished extracting features\n"
     ]
    }
   ],
   "source": [
    "train_x = extractFeatures(newModel, train_x)\n",
    "\n",
    "val_x = extractFeatures(newModel, val_x)\n",
    "print(\"Finished extracting features\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted features\n",
      "(32645, 4608)\n",
      "(32645,)\n",
      "(8166, 4608)\n",
      "(8166,)\n"
     ]
    }
   ],
   "source": [
    "#now save the extracted features\n",
    "np.save(\"./extractedFeatures/train_x.npy\", train_x)\n",
    "np.save(\"./extractedFeatures/train_y.npy\", train_y)\n",
    "np.save(\"./extractedFeatures/val_x.npy\", val_x)\n",
    "np.save(\"./extractedFeatures/val_y.npy\", val_y)\n",
    "\n",
    "print(\"Saved extracted features\")\n",
    "\n",
    "#print the shape of the extracted features\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded extracted features\n",
      "(32645, 4608)\n",
      "(32645,)\n",
      "(8166, 4608)\n",
      "(8166,)\n"
     ]
    }
   ],
   "source": [
    "#load the saved features\n",
    "train_x = np.load(\"./extractedFeatures/train_x.npy\")\n",
    "train_y = np.load(\"./extractedFeatures/train_y.npy\")\n",
    "val_x = np.load(\"./extractedFeatures/val_x.npy\")\n",
    "val_y = np.load(\"./extractedFeatures/val_y.npy\")\n",
    "\n",
    "print(\"Loaded extracted features\")\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32645, 4608)\n",
      "(32645,)\n",
      "(8166, 4608)\n",
      "(8166,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#the shape is (32645, 4608). \n",
    "#The first dimension is the number of images\n",
    "#The second dimension is the number of features extracted from the model\n",
    "\n",
    "#take only the first 128 features\n",
    "train_x = train_x[:, :]\n",
    "val_x = val_x[:, :]\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN with k = 1\n",
      "The accuracy is: 0.6729120744550575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.57      0.50      0.53       991\n",
      "    CONTEMPT       0.95      0.95      0.95       524\n",
      "     DISGUST       0.91      0.89      0.90       571\n",
      "        FEAR       0.49      0.48      0.49      1025\n",
      "   HAPPINESS       0.85      0.82      0.84      1798\n",
      "     NEUTRAL       0.57      0.57      0.57      1240\n",
      "     SADNESS       0.49      0.57      0.53      1216\n",
      "    SURPRISE       0.76      0.77      0.76       801\n",
      "\n",
      "    accuracy                           0.67      8166\n",
      "   macro avg       0.70      0.69      0.70      8166\n",
      "weighted avg       0.68      0.67      0.67      8166\n",
      "\n",
      "KNN with k = 2\n",
      "The accuracy is: 0.6471956894440363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.46      0.60      0.52       991\n",
      "    CONTEMPT       0.90      0.96      0.93       524\n",
      "     DISGUST       0.93      0.83      0.88       571\n",
      "        FEAR       0.40      0.52      0.45      1025\n",
      "   HAPPINESS       0.82      0.85      0.84      1798\n",
      "     NEUTRAL       0.55      0.56      0.55      1240\n",
      "     SADNESS       0.57      0.36      0.44      1216\n",
      "    SURPRISE       0.88      0.63      0.74       801\n",
      "\n",
      "    accuracy                           0.65      8166\n",
      "   macro avg       0.69      0.67      0.67      8166\n",
      "weighted avg       0.66      0.65      0.65      8166\n",
      "\n",
      "KNN with k = 3\n",
      "The accuracy is: 0.6697281410727406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.48      0.56      0.52       991\n",
      "    CONTEMPT       0.93      0.93      0.93       524\n",
      "     DISGUST       0.91      0.84      0.87       571\n",
      "        FEAR       0.45      0.46      0.45      1025\n",
      "   HAPPINESS       0.86      0.85      0.86      1798\n",
      "     NEUTRAL       0.61      0.57      0.59      1240\n",
      "     SADNESS       0.52      0.53      0.52      1216\n",
      "    SURPRISE       0.82      0.74      0.78       801\n",
      "\n",
      "    accuracy                           0.67      8166\n",
      "   macro avg       0.70      0.69      0.69      8166\n",
      "weighted avg       0.68      0.67      0.67      8166\n",
      "\n",
      "KNN with k = 4\n",
      "The accuracy is: 0.6765858437423463\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.54      0.54      0.54       991\n",
      "    CONTEMPT       0.91      0.95      0.93       524\n",
      "     DISGUST       0.93      0.82      0.87       571\n",
      "        FEAR       0.47      0.47      0.47      1025\n",
      "   HAPPINESS       0.87      0.86      0.86      1798\n",
      "     NEUTRAL       0.58      0.63      0.60      1240\n",
      "     SADNESS       0.51      0.53      0.52      1216\n",
      "    SURPRISE       0.83      0.71      0.76       801\n",
      "\n",
      "    accuracy                           0.68      8166\n",
      "   macro avg       0.70      0.69      0.69      8166\n",
      "weighted avg       0.68      0.68      0.68      8166\n",
      "\n",
      "KNN with k = 5\n",
      "The accuracy is: 0.6783002694097477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.55      0.53      0.54       991\n",
      "    CONTEMPT       0.94      0.92      0.93       524\n",
      "     DISGUST       0.91      0.84      0.88       571\n",
      "        FEAR       0.47      0.46      0.47      1025\n",
      "   HAPPINESS       0.86      0.86      0.86      1798\n",
      "     NEUTRAL       0.57      0.63      0.60      1240\n",
      "     SADNESS       0.51      0.55      0.53      1216\n",
      "    SURPRISE       0.82      0.73      0.77       801\n",
      "\n",
      "    accuracy                           0.68      8166\n",
      "   macro avg       0.71      0.69      0.70      8166\n",
      "weighted avg       0.68      0.68      0.68      8166\n",
      "\n",
      "KNN with k = 6\n",
      "The accuracy is: 0.6798922361009062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.56      0.53      0.54       991\n",
      "    CONTEMPT       0.90      0.92      0.91       524\n",
      "     DISGUST       0.93      0.81      0.86       571\n",
      "        FEAR       0.48      0.46      0.47      1025\n",
      "   HAPPINESS       0.87      0.87      0.87      1798\n",
      "     NEUTRAL       0.57      0.64      0.60      1240\n",
      "     SADNESS       0.52      0.56      0.54      1216\n",
      "    SURPRISE       0.83      0.72      0.77       801\n",
      "\n",
      "    accuracy                           0.68      8166\n",
      "   macro avg       0.71      0.69      0.70      8166\n",
      "weighted avg       0.69      0.68      0.68      8166\n",
      "\n",
      "KNN with k = 7\n",
      "The accuracy is: 0.6809943668870928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.57      0.51      0.54       991\n",
      "    CONTEMPT       0.92      0.91      0.91       524\n",
      "     DISGUST       0.91      0.82      0.86       571\n",
      "        FEAR       0.48      0.43      0.46      1025\n",
      "   HAPPINESS       0.88      0.86      0.87      1798\n",
      "     NEUTRAL       0.58      0.65      0.61      1240\n",
      "     SADNESS       0.50      0.59      0.54      1216\n",
      "    SURPRISE       0.82      0.73      0.78       801\n",
      "\n",
      "    accuracy                           0.68      8166\n",
      "   macro avg       0.71      0.69      0.70      8166\n",
      "weighted avg       0.69      0.68      0.68      8166\n",
      "\n",
      "KNN with k = 8\n",
      "The accuracy is: 0.6771981386235612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.58      0.51      0.54       991\n",
      "    CONTEMPT       0.91      0.92      0.91       524\n",
      "     DISGUST       0.92      0.80      0.86       571\n",
      "        FEAR       0.49      0.43      0.46      1025\n",
      "   HAPPINESS       0.87      0.86      0.87      1798\n",
      "     NEUTRAL       0.57      0.66      0.61      1240\n",
      "     SADNESS       0.49      0.58      0.53      1216\n",
      "    SURPRISE       0.82      0.72      0.77       801\n",
      "\n",
      "    accuracy                           0.68      8166\n",
      "   macro avg       0.71      0.68      0.69      8166\n",
      "weighted avg       0.69      0.68      0.68      8166\n",
      "\n",
      "KNN with k = 9\n",
      "The accuracy is: 0.6823414156257653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.59      0.51      0.55       991\n",
      "    CONTEMPT       0.92      0.91      0.91       524\n",
      "     DISGUST       0.91      0.81      0.86       571\n",
      "        FEAR       0.51      0.42      0.46      1025\n",
      "   HAPPINESS       0.88      0.86      0.87      1798\n",
      "     NEUTRAL       0.57      0.66      0.61      1240\n",
      "     SADNESS       0.49      0.60      0.54      1216\n",
      "    SURPRISE       0.81      0.74      0.77       801\n",
      "\n",
      "    accuracy                           0.68      8166\n",
      "   macro avg       0.71      0.69      0.70      8166\n",
      "weighted avg       0.69      0.68      0.68      8166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#train a knn classifier\n",
    "for i in range(1, 10):\n",
    "    print(\"KNN with k = \" + str(i))\n",
    "    classifier = KNeighborsClassifier(n_neighbors=i)\n",
    "    classifier.fit(train_x, train_y)\n",
    "\n",
    "    #save the model using pickle\n",
    "    filename = './models/KNN' + str(i) + '.pickle'\n",
    "    pickle.dump(classifier, open(filename, 'wb'))\n",
    "\n",
    "    pred = classifier.predict(val_x)\n",
    "    #print(pred)\n",
    "\n",
    "    #evaluate the model\n",
    "    print(\"The accuracy is: \" + str(accuracy_score(val_y, pred)))\n",
    "\n",
    "    #print the report of the model\n",
    "    print(sklearn.metrics.classification_report(val_y, pred))\n",
    "\n",
    "    #save the preds\n",
    "    np.save(\"./risults/KNN\" + str(i) + \".npy\", pred)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.6699730590252265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.58      0.52      0.55       991\n",
      "    CONTEMPT       0.88      0.88      0.88       524\n",
      "     DISGUST       0.91      0.70      0.79       571\n",
      "        FEAR       0.50      0.28      0.36      1025\n",
      "   HAPPINESS       0.91      0.84      0.87      1798\n",
      "     NEUTRAL       0.57      0.69      0.62      1240\n",
      "     SADNESS       0.47      0.65      0.55      1216\n",
      "    SURPRISE       0.73      0.81      0.77       801\n",
      "\n",
      "    accuracy                           0.67      8166\n",
      "   macro avg       0.69      0.67      0.67      8166\n",
      "weighted avg       0.68      0.67      0.67      8166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a naive bayes classifier from sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(train_x, train_y)\n",
    "\n",
    "#evaluate the model\n",
    "pred = classifier.predict(val_x)\n",
    "print(\"The accuracy is: \" + str(accuracy_score(val_y, pred)))\n",
    "\n",
    "#save the model using pickle\n",
    "filename = './models/NaiveBayes.pickle'\n",
    "pickle.dump(classifier, open(filename, 'wb'))\n",
    "\n",
    "#save the preds\n",
    "np.save(\"./risults/NaiveBayes.npy\", pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(sklearn.metrics.classification_report(val_y, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n",
      "The accuracy is: 0.6705853539064414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.50      0.58      0.53       991\n",
      "    CONTEMPT       0.95      0.95      0.95       524\n",
      "     DISGUST       0.91      0.89      0.90       571\n",
      "        FEAR       0.45      0.49      0.47      1025\n",
      "   HAPPINESS       0.85      0.86      0.85      1798\n",
      "     NEUTRAL       0.59      0.54      0.57      1240\n",
      "     SADNESS       0.51      0.47      0.49      1216\n",
      "    SURPRISE       0.81      0.77      0.79       801\n",
      "\n",
      "    accuracy                           0.67      8166\n",
      "   macro avg       0.70      0.69      0.69      8166\n",
      "weighted avg       0.67      0.67      0.67      8166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a svm classifier\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(train_x, train_y)\n",
    "\n",
    "#save the model using pickle\n",
    "filename = './models/SVMlinear.pickle'\n",
    "pickle.dump(classifier, open(filename, 'wb'))\n",
    "\n",
    "print(\"Model saved\")\n",
    "\n",
    "pred = classifier.predict(val_x)\n",
    "\n",
    "#evaluate the model\n",
    "print(\"The accuracy is: \" + str(accuracy_score(val_y, pred)))\n",
    "\n",
    "#save the preds\n",
    "np.save(\"./risults/SVMlinear.npy\", pred)\n",
    "\n",
    "print(sklearn.metrics.classification_report(val_y, pred))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Predicted\n",
      "The accuracy is: 0.6705853539064414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.50      0.58      0.53       991\n",
      "    CONTEMPT       0.95      0.95      0.95       524\n",
      "     DISGUST       0.91      0.89      0.90       571\n",
      "        FEAR       0.45      0.49      0.47      1025\n",
      "   HAPPINESS       0.85      0.86      0.85      1798\n",
      "     NEUTRAL       0.59      0.54      0.57      1240\n",
      "     SADNESS       0.51      0.47      0.49      1216\n",
      "    SURPRISE       0.81      0.77      0.79       801\n",
      "\n",
      "    accuracy                           0.67      8166\n",
      "   macro avg       0.70      0.69      0.69      8166\n",
      "weighted avg       0.67      0.67      0.67      8166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load the svm linear model\n",
    "filename = './models/SVMlinear.pickle'\n",
    "classifier = pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "print(\"Model loaded\")\n",
    "\n",
    "pred = classifier.predict(val_x)\n",
    "\n",
    "print(\"Predicted\")\n",
    "\n",
    "#evaluate the model\n",
    "print(\"The accuracy is: \" + str(accuracy_score(val_y, pred)))\n",
    "\n",
    "#save the preds\n",
    "np.save(\"./risults/SVMlinear.npy\", pred)\n",
    "\n",
    "print(sklearn.metrics.classification_report(val_y, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained\n",
      "Model saved\n",
      "Degree 2   The accuracy is: 0.7116091109478325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.66      0.54      0.59       991\n",
      "    CONTEMPT       0.97      0.93      0.95       524\n",
      "     DISGUST       0.93      0.87      0.90       571\n",
      "        FEAR       0.58      0.45      0.51      1025\n",
      "   HAPPINESS       0.87      0.88      0.88      1798\n",
      "     NEUTRAL       0.62      0.65      0.64      1240\n",
      "     SADNESS       0.50      0.68      0.57      1216\n",
      "    SURPRISE       0.82      0.75      0.78       801\n",
      "\n",
      "    accuracy                           0.71      8166\n",
      "   macro avg       0.74      0.72      0.73      8166\n",
      "weighted avg       0.72      0.71      0.71      8166\n",
      "\n",
      "Model trained\n",
      "Model saved\n",
      "Degree 3   The accuracy is: 0.6987509184423218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.70      0.50      0.58       991\n",
      "    CONTEMPT       0.97      0.92      0.94       524\n",
      "     DISGUST       0.94      0.87      0.90       571\n",
      "        FEAR       0.62      0.41      0.49      1025\n",
      "   HAPPINESS       0.89      0.87      0.88      1798\n",
      "     NEUTRAL       0.64      0.62      0.63      1240\n",
      "     SADNESS       0.44      0.75      0.55      1216\n",
      "    SURPRISE       0.84      0.72      0.78       801\n",
      "\n",
      "    accuracy                           0.70      8166\n",
      "   macro avg       0.75      0.71      0.72      8166\n",
      "weighted avg       0.73      0.70      0.70      8166\n",
      "\n",
      "Model trained\n",
      "Model saved\n",
      "Degree 4   The accuracy is: 0.6675238795003674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.72      0.46      0.56       991\n",
      "    CONTEMPT       0.96      0.91      0.93       524\n",
      "     DISGUST       0.94      0.85      0.89       571\n",
      "        FEAR       0.64      0.35      0.45      1025\n",
      "   HAPPINESS       0.90      0.81      0.85      1798\n",
      "     NEUTRAL       0.67      0.54      0.60      1240\n",
      "     SADNESS       0.37      0.82      0.51      1216\n",
      "    SURPRISE       0.85      0.68      0.76       801\n",
      "\n",
      "    accuracy                           0.67      8166\n",
      "   macro avg       0.76      0.68      0.69      8166\n",
      "weighted avg       0.73      0.67      0.68      8166\n",
      "\n",
      "Model trained\n",
      "Model saved\n",
      "Degree 5   The accuracy is: 0.6238060249816312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.71      0.42      0.53       991\n",
      "    CONTEMPT       0.95      0.87      0.91       524\n",
      "     DISGUST       0.93      0.83      0.88       571\n",
      "        FEAR       0.66      0.30      0.41      1025\n",
      "   HAPPINESS       0.91      0.75      0.82      1798\n",
      "     NEUTRAL       0.68      0.43      0.53      1240\n",
      "     SADNESS       0.32      0.85      0.46      1216\n",
      "    SURPRISE       0.86      0.65      0.74       801\n",
      "\n",
      "    accuracy                           0.62      8166\n",
      "   macro avg       0.75      0.64      0.66      8166\n",
      "weighted avg       0.73      0.62      0.64      8166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a svm classifier\n",
    "from sklearn.svm import SVC\n",
    "for degree in range(2, 6):\n",
    "    classifier = SVC(kernel='poly', degree=degree) #by default the degree is 3\n",
    "    classifier.fit(train_x, train_y)\n",
    "\n",
    "    print(\"Model trained\")\n",
    "\n",
    "    #save the model using pickle\n",
    "    filename = './models/SVMpoly' + str(degree) + '.pickle'\n",
    "    pickle.dump(classifier, open(filename, 'wb'))\n",
    "\n",
    "    \n",
    "\n",
    "    print(\"Model saved\")\n",
    "    pred = classifier.predict(val_x)\n",
    "\n",
    "    #evaluate the model\n",
    "    print(f\"Degree {degree}   The accuracy is: \" + str(accuracy_score(val_y, pred)))\n",
    "\n",
    "    print(sklearn.metrics.classification_report(val_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained\n",
      "Model saved\n",
      "The accuracy is: 0.7228753367621846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.63      0.58      0.60       991\n",
      "    CONTEMPT       0.97      0.93      0.95       524\n",
      "     DISGUST       0.91      0.88      0.90       571\n",
      "        FEAR       0.59      0.48      0.53      1025\n",
      "   HAPPINESS       0.87      0.89      0.88      1798\n",
      "     NEUTRAL       0.63      0.68      0.65      1240\n",
      "     SADNESS       0.55      0.63      0.59      1216\n",
      "    SURPRISE       0.80      0.80      0.80       801\n",
      "\n",
      "    accuracy                           0.72      8166\n",
      "   macro avg       0.74      0.73      0.74      8166\n",
      "weighted avg       0.72      0.72      0.72      8166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a svm classifier\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='rbf')\n",
    "classifier.fit(train_x, train_y)\n",
    "\n",
    "print(\"Model trained\")\n",
    "\n",
    "#save the model using pickle\n",
    "filename = './models/SVMrbf.pickle'\n",
    "pickle.dump(classifier, open(filename, 'wb'))\n",
    "\n",
    "print(\"Model saved\")\n",
    "\n",
    "pred = classifier.predict(val_x)\n",
    "\n",
    "#evaluate the model\n",
    "print(\"The accuracy is: \" + str(accuracy_score(val_y, pred)))\n",
    "\n",
    "print(sklearn.metrics.classification_report(val_y, classifier.predict(val_x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proviamo il magiko softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(theta, X):\n",
    "    '''\n",
    "    Function to compute associated probability for each sample and each class.\n",
    "    \n",
    "    Input:\n",
    "    theta: it's the model parameter matrix. The shape is (H, K)\n",
    "    X: it's the input data matrix. The shape is (N, H)\n",
    "\n",
    "    Output:\n",
    "    softmax: it's the matrix containing probability for each sample and each class. The shape is (N, K)\n",
    "    '''\n",
    "    \n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    #softmax is defined as exp(theta.T * X) / sum(exp(theta.T * X))\n",
    "\n",
    "    #initialize softmax\n",
    "    softmax = np.zeros((X.shape[0], theta.shape[1]))\n",
    "\n",
    "    #for i in range(X.shape[0]):    #this version is slower\n",
    "    #    softmax[i] = np.exp(np.dot(theta.T, X[i])) / np.sum(np.exp(np.dot(theta.T, X[i])))\n",
    "\n",
    "    #vectorized implementation, faster\n",
    "    softmax = np.exp(np.dot(X, theta)) / np.sum(np.exp(np.dot(X, theta)), axis=1).reshape(X.shape[0] ,1)\n",
    "    #print(softmax.shape)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    return softmax\n",
    "\n",
    "\n",
    "def CELoss(theta, X, y_onehot):     \n",
    "    '''\n",
    "    Function to compute softmax regression model and Cross Entropy loss.\n",
    "    \n",
    "    Input:\n",
    "    theta: it's the model parameter matrix. The shape is (H, K)\n",
    "    X: it's the input data matrix. The shape is (N, H)\n",
    "    y_onehot: it's the label array in encoded as one hot vector. The shape is (N, K)\n",
    "\n",
    "    Output:\n",
    "    loss: The scalar that is the mean error for each sample.\n",
    "    '''\n",
    "    \n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    #compute the softmax using the above defined function\n",
    "    softmax1 = softmax(theta, X)\n",
    "\n",
    "    #we compute the loss for each sample and then we sum them up\n",
    "    loss = -np.sum(y_onehot * np.log(softmax1)) / X.shape[0]\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def CELoss_jacobian(theta, X, y_onehot):\n",
    "    '''\n",
    "    Function to compute gradient of the cross entropy loss with respect the parameters.\n",
    "    \n",
    "    Input:\n",
    "    theta: it's the model parameter matrix. The shape is (H, K)\n",
    "    X: it's the input data matrix. The shape is (N, H)\n",
    "    y_onehot: it's the label array in encoded as one hot vector. The shape is (N, K)\n",
    "\n",
    "    Output:\n",
    "    jacobian: A matrix with the partial derivatives of the loss. The shape is (H, K)\n",
    "    '''\n",
    "\n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    softmax1 = softmax(theta, X)\n",
    "    jacobian = np.dot(X.T, (softmax1 - y_onehot)) / X.shape[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    return jacobian\n",
    "\n",
    "\n",
    "def gradient_descent(theta, X, y_onehot, alpha=0.01, iterations=100):\n",
    "    '''\n",
    "    Function to compute gradient of the cross entropy loss with respect the parameters.\n",
    "    \n",
    "    Input:\n",
    "    theta: it's the model parameter matrix. The shape is (H, K)\n",
    "    X: it's the input data matrix. The shape is (N, H)\n",
    "    y_onehot: it's the label array in encoded as one hot vector. The shape is (N, K)\n",
    "    alpha: it's the learning rate, so it determines the speed of each step of the GD algorithm\n",
    "    iterations: it's the total number of step the algorithm performs\n",
    "\n",
    "    Output:\n",
    "    theta: it's the updated matrix of the parameters after all the iterations of the optimization algorithm. The shape is (H, K)\n",
    "    loss_history: it's an array with the computed loss after each iteration\n",
    "    '''\n",
    "\n",
    "    # We initialize an empty array to be filled with loss value after each iteration\n",
    "    loss_history = np.zeros(iterations)\n",
    "    \n",
    "    # With a for loop we compute the steps of GD algo\n",
    "    #use tqdm\n",
    "    for it in tqdm.tqdm(range(iterations)):\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        #####################################################\n",
    "        ##                 YOUR CODE HERE                  ##\n",
    "        #####################################################\n",
    "        #print(\"Iterazione numero: %d\",  it)\n",
    "        loss = CELoss(theta, X, y_onehot)\n",
    "        gradient = CELoss_jacobian(theta, X, y_onehot)\n",
    "        theta = theta - alpha * gradient\n",
    "        loss_history[it] = loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return theta, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape:  (32645, 48, 48)\n",
      "train_y shape:  (32645, 8)\n",
      "val_x shape:  (8166, 48, 48)\n",
      "val_y shape:  (8166, 8)\n",
      "1021/1021 [==============================] - 5s 5ms/step\n",
      "256/256 [==============================] - 1s 5ms/step\n",
      "train_x_extracted shape:  (32645, 4608)\n",
      "val_x_extracted shape:  (8166, 4608)\n"
     ]
    }
   ],
   "source": [
    "path = \"./dataset/GoogleFer/\"\n",
    "test_path = path + \"val/\"\n",
    "train_path = path + \"train/\"\n",
    "\n",
    "classes = { \"anger\" : 0,  \"contempt\" : 1,  \"disgust\" : 2,  \"fear\" : 3,  \"happiness\" : 4,  \"sadness\" : 5,  \"surprise\" : 6,  \"neutral\" : 7}\n",
    "\n",
    "classesReversed = { 0 : \"anger\" ,  1 : \"contempt\" ,  2 : \"disgust\" ,  3 : \"fear\" ,  4 : \"happiness\" ,  5 : \"sadness\" ,  6 : \"surprise\" ,  7 : \"neutral\" }\n",
    "num_classes = 8\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "val_x = []\n",
    "val_y = []\n",
    "\n",
    "#load the train data\n",
    "\n",
    "\n",
    "\n",
    "contClassesTrain = { \"anger\" : 0,  \"contempt\" : 0,  \"disgust\" : 0,  \"fear\" : 0,  \"happiness\" : 0,  \"sadness\" : 0,  \"surprise\" : 0,  \"neutral\" : 0}\n",
    "contClassesTest = { \"anger\" : 0,  \"contempt\" : 0,  \"disgust\" : 0,  \"fear\" : 0,  \"happiness\" : 0,  \"sadness\" : 0,  \"surprise\" : 0,  \"neutral\" : 0}\n",
    "\n",
    "\n",
    "\n",
    "for i in classes:\n",
    "        #convert i to upper case\n",
    "        #i = i.upper()    \n",
    "        path = os.path.join(train_path, i.upper())\n",
    "            \n",
    "        for img in os.listdir(path):\n",
    "                img_array = cv2.imread (os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                #new_array = cv2.resize(img_array, (48, 48))\n",
    "                train_x.append(img_array)\n",
    "                train_y.append(classes[i])\n",
    "                contClassesTrain[i] = contClassesTrain[i] + 1\n",
    "\n",
    "#load the test data\n",
    "for i in classes:\n",
    "        #i = i.upper()  \n",
    "        path = os.path.join(test_path, i.upper())\n",
    "        \n",
    "            \n",
    "        for img in os.listdir(path):\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                #new_array = cv2.resize(img_array, (48, 48))\n",
    "                val_x.append(img_array)\n",
    "                val_y.append(classes[i])\n",
    "                contClassesTest[i] = contClassesTest[i] + 1\n",
    "\n",
    "#convert the val_x and train_x to numpy array\n",
    "train_x = np.array(train_x)\n",
    "train_y = keras.utils.to_categorical(train_y, 8)\n",
    "val_x = np.array(val_x)\n",
    "val_y = keras.utils.to_categorical(val_y, 8)\n",
    "\n",
    "print ( \"train_x shape: \" , train_x.shape)\n",
    "print ( \"train_y shape: \" , train_y.shape)\n",
    "print ( \"val_x shape: \" , val_x.shape)\n",
    "print ( \"val_y shape: \" , val_y.shape)\n",
    "\n",
    "\n",
    "train_x = train_x / 255.0\n",
    "val_x = val_x / 255.0\n",
    "\n",
    "train_x_extracted = extractFeatures(newModel, train_x)\n",
    "val_x_extracted = extractFeatures(newModel, val_x)\n",
    "\n",
    "print ( \"train_x_extracted shape: \" , train_x_extracted.shape)\n",
    "print ( \"val_x_extracted shape: \" , val_x_extracted.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45495/2262461121.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.sum(y_onehot * np.log(softmax1)) / X.shape[0]\n",
      "/tmp/ipykernel_45495/2262461121.py:56: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.sum(y_onehot * np.log(softmax1)) / X.shape[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 1/20 [00:03<01:00,  3.19s/it]/tmp/ipykernel_45495/2262461121.py:26: RuntimeWarning: overflow encountered in exp\n",
      "  softmax = np.exp(np.dot(X, theta)) / np.sum(np.exp(np.dot(X, theta)), axis=1).reshape(X.shape[0] ,1)\n",
      "/tmp/ipykernel_45495/2262461121.py:26: RuntimeWarning: invalid value encountered in divide\n",
      "  softmax = np.exp(np.dot(X, theta)) / np.sum(np.exp(np.dot(X, theta)), axis=1).reshape(X.shape[0] ,1)\n",
      "100%|| 20/20 [00:49<00:00,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "theta0 = np.random.randn(train_x_extracted.shape[1], 8)\n",
    "theta0.shape\n",
    "\n",
    "\n",
    "print(\"Initial loss: \", CELoss(theta0, train_x_extracted, train_y))\n",
    "\n",
    "theta, loss_history = gradient_descent(theta0, train_x_extracted, train_y, alpha=1e3, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = CELoss(theta, train_x_extracted, train_y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(theta, X, y):\n",
    "    '''\n",
    "    Function to compute accuracy metrics of the softmax regression model.\n",
    "    \n",
    "    Input:\n",
    "    theta: it's the final parameter matrix. The one we learned after all the iterations of the GD algorithm. The shape is (H, K)\n",
    "    X: it's the input data matrix. The shape is (N, H)\n",
    "    y: it's the label array. The shape is (N, 1)\n",
    "\n",
    "    Output:\n",
    "    accuracy: Score of the accuracy.\n",
    "    '''\n",
    "    \n",
    "    #####################################################\n",
    "    ##                 YOUR CODE HERE                  ##\n",
    "    #####################################################\n",
    "\n",
    "    accuracy = 0\n",
    "\n",
    "    accuracy = np.sum(np.argmax(softmax(theta, X), axis=1) == y) / X.shape[0]\n",
    "\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12135684545677199"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(theta, val_x_extracted, np.argmax(val_y, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
